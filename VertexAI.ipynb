{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarimaSolanki18/VertexAI/blob/main/VertexAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "ULLORxwt26Mv",
        "outputId": "6abdce78-ca8b-4a46-e897-34128a291dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.54.1)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.56.0-py2.py3-none-any.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.7.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.6.2)\n",
            "Installing collected packages: google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.56.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "43fa4a2966e148699b3e5ddb501ace6e",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1uwtUEVQ8vWK",
        "outputId": "b553cb86-5b16-4501-c5b3-b7c9de219ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ragstack-ai\n",
            "  Using cached ragstack_ai-1.0.8-py3-none-any.whl (4.2 kB)\n",
            "Collecting ragstack-ai-colbert==1.0.5 (from ragstack-ai)\n",
            "  Using cached ragstack_ai_colbert-1.0.5-py3-none-any.whl (20 kB)\n",
            "Collecting ragstack-ai-langchain[colbert,google,nvidia]==1.1.0 (from ragstack-ai)\n",
            "  Using cached ragstack_ai_langchain-1.1.0-py3-none-any.whl (4.9 kB)\n",
            "Collecting ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6 (from ragstack-ai)\n",
            "  Using cached ragstack_ai_llamaindex-1.0.6-py3-none-any.whl (3.1 kB)\n",
            "Collecting cassio<0.2.0,>=0.1.7 (from ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached cassio-0.1.8-py3-none-any.whl (45 kB)\n",
            "Collecting colbert-ai==0.2.19 (from ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached colbert-ai-0.2.19.tar.gz (86 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyarrow==14.0.1 (from ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-colbert==1.0.5->ragstack-ai) (2.7.3)\n",
            "Collecting torch==2.2.1 (from ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astrapy<2,>=1 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading astrapy-1.2.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.2.3 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-astradb==0.3.3 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_astradb-0.3.3-py3-none-any.whl (27 kB)\n",
            "Collecting langchain-community==0.2.4 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.2.5 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai==0.1.8 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
            "Collecting unstructured==0.14.2 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading unstructured-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-genai==1.0.6 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_google_genai-1.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting langchain-google-vertexai==1.0.5 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_google_vertexai-1.0.5-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-nvidia-ai-endpoints==0.1.1 (from ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.1.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (1.16.0)\n",
            "Collecting llama-index==0.10.43 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index-0.10.43-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-core==0.10.43 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_core-0.10.43-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-langchain==0.1.2 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\n",
            "Collecting llama-index-tools-cassandra==0.1.1 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_tools_cassandra-0.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting llama-index-vector-stores-astra-db==0.1.7 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_vector_stores_astra_db-0.1.7-py3-none-any.whl (6.1 kB)\n",
            "Collecting llama-index-vector-stores-cassandra==0.1.3 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_vector_stores_cassandra-0.1.3-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-parse==0.4.1 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_parse-0.4.1-py3-none-any.whl (7.3 kB)\n",
            "Collecting llama-index-embeddings-bedrock==0.1.4 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_embeddings_bedrock-0.1.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting llama-index-llms-bedrock==0.1.7 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_llms_bedrock-0.1.7-py3-none-any.whl (8.2 kB)\n",
            "Collecting llama-index-embeddings-azure-openai==0.1.7 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_embeddings_azure_openai-0.1.7-py3-none-any.whl (3.1 kB)\n",
            "Collecting llama-index-llms-azure-openai==0.1.6 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_llms_azure_openai-0.1.6-py3-none-any.whl (4.8 kB)\n",
            "Collecting llama-index-embeddings-gemini==0.1.7 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_embeddings_gemini-0.1.7-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-llms-gemini==0.1.10 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_llms_gemini-0.1.10-py3-none-any.whl (4.9 kB)\n",
            "Collecting llama-index-llms-vertex==0.1.5 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_llms_vertex-0.1.5-py3-none-any.whl (7.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-gemini==0.1.7 (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_multi_modal_llms_gemini-0.1.7-py3-none-any.whl (3.9 kB)\n",
            "Collecting bitarray (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.2.5)\n",
            "Collecting git-python (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting python-dotenv (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting ninja (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (4.66.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (4.41.2)\n",
            "Collecting ujson (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langsmith-0.1.80-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (8.3.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.2.4->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.2.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core==0.2.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.5.4)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.47.0 in /root/.local/lib/python3.10/site-packages (from langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.56.0)\n",
            "Collecting google-cloud-storage<3.0.0,>=2.14.0 (from langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow<11.0.0,>=10.0.0 (from langchain-nvidia-ai-endpoints==0.1.1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.26.0 (from langchain-openai==0.1.8->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai==0.1.8->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_llms_openai-0.1.22-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_readers_file-0.1.25-py3-none-any.whl (37 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (1.14.1)\n",
            "Collecting boto3<2.0.0,>=1.34.23 (from llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading boto3-1.34.129-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-identity<2.0.0,>=1.15.0 (from llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading azure_identity-1.17.0-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-anthropic<0.2.0,>=0.1.7 (from llama-index-llms-bedrock==0.1.7->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading llama_index_llms_anthropic-0.1.13-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (4.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (4.12.3)\n",
            "Collecting emoji (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-iso639 (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting unstructured-client (from unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading unstructured_client-0.23.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bson<0.6.0,>=0.5.10 (from astrapy<2,>=1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading bson-0.5.10.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy<2,>=1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from astrapy<2,>=1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.10.2)\n",
            "Collecting uuid6<2024.2.0,>=2024.1.12 (from astrapy<2,>=1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading uuid6-2024.1.12-py3-none-any.whl (6.4 kB)\n",
            "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio<0.2.0,>=0.1.7->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading cassandra_driver-3.29.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.16.0->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2.22)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.18.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.9.4)\n",
            "Collecting azure-core>=1.23.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (42.0.8)\n",
            "Collecting msal>=1.24.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading msal-1.28.1-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal-extensions>=0.3.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
            "Collecting botocore<1.35.0,>=1.34.129 (from boto3<2.0.0,>=1.34.23->llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading botocore-1.34.129-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.23->llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.23->llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from bson<0.6.0,>=0.5.10->astrapy<2,>=1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bson<0.6.0,>=0.5.10->astrapy<2,>=1->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.16.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.7->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.4->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (3.20.3)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.0.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.16)\n",
            "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.7.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.5.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.6.4)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.84.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (1.3.1)\n",
            "Collecting h2<5,>=3 (from httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.2.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m697.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anthropic<0.29.0,>=0.26.2 (from llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.7->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading anthropic-0.28.1-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.7/862.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai==0.1.8->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2 (from langchain==0.2.3->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.23.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.1.5)\n",
            "Collecting gitpython (from git-python->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.4.3)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiter<1,>=0.4.0 (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.7->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (1.2.1)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured==0.14.2->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.63.1)\n",
            "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.13.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx->llama-index-core==0.10.43->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai) (2.3.0)\n",
            "Collecting portalocker<3,>=1.0 (from msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.6->ragstack-ai)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.6->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.5->ragstack-ai-langchain[colbert,google,nvidia]==1.1.0->ragstack-ai) (0.6.0)\n",
            "Building wheels for collected packages: colbert-ai, bson, langdetect\n",
            "  Building wheel for colbert-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114762 sha256=dc18db139a6a3c54b1a915ecc00d4486f419fafcc98db47af72dc096c1c63d01\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
            "  Building wheel for bson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bson: filename=bson-0.5.10-py3-none-any.whl size=11976 sha256=f2aa95598f2e5823d759e25cb7b15e913c0bd16658d9264fc8acf9ad3c239e87\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/49/3b/8b33954dfae7a176009c4d721a45af56c8a9c1cdc3ee947945\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=d04fbb4b6c904695cf0ab96495584280acf17c10ce8cb1adb5e42e8ffc09b752\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built colbert-ai bson langdetect\n",
            "Installing collected packages: striprtf, ninja, filetype, dirtyjson, bitarray, xxhash, uuid6, ujson, triton, smmap, requests, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, pyarrow, portalocker, pillow, packaging, orjson, ordered-set, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, langdetect, jsonpointer, jsonpath-python, jmespath, jiter, hyperframe, hpack, h11, geomet, emoji, dill, deprecated, backoff, typing-inspect, tiktoken, requests-toolbelt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, marshmallow, jsonpatch, httpcore, h2, gitdb, deprecation, deepdiff, cassandra-driver, bson, botocore, azure-core, s3transfer, nvidia-cusolver-cu12, langsmith, httpx, google-api-core, gitpython, dataclasses-json, cassio, unstructured-client, torch, openai, msal, llamaindex-py-client, langchain-core, git-python, datasets, boto3, anthropic, unstructured, msal-extensions, llama-index-legacy, llama-index-core, langchain-text-splitters, langchain-openai, langchain-nvidia-ai-endpoints, google-cloud-storage, colbert-ai, astrapy, ragstack-ai-colbert, llama-parse, llama-index-vector-stores-cassandra, llama-index-vector-stores-astra-db, llama-index-tools-cassandra, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-anthropic, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-langchain, llama-index-embeddings-bedrock, langchain-astradb, langchain, azure-identity, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-vertex, llama-index-llms-gemini, llama-index-llms-bedrock, llama-index-llms-azure-openai, llama-index-embeddings-gemini, llama-index-cli, llama-index-agent-openai, langchain-google-vertexai, langchain-google-genai, langchain-community, ragstack-ai-langchain, llama-index-program-openai, llama-index-multi-modal-llms-gemini, llama-index-embeddings-azure-openai, llama-index-question-gen-openai, llama-index, ragstack-ai-llamaindex, ragstack-ai\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.28.1 astrapy-1.2.1 azure-core-1.30.2 azure-identity-1.17.0 backoff-2.2.1 bitarray-2.9.2 boto3-1.34.129 botocore-1.34.129 bson-0.5.10 cassandra-driver-3.29.1 cassio-0.1.8 colbert-ai-0.2.19 dataclasses-json-0.6.7 datasets-2.19.2 deepdiff-7.0.1 deprecated-1.2.14 deprecation-2.1.0 dill-0.3.8 dirtyjson-1.0.8 emoji-2.12.1 filetype-1.2.0 geomet-0.2.1.post1 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.19.0 google-cloud-storage-2.17.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 jiter-0.4.2 jmespath-1.0.1 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-3.0.0 langchain-0.2.3 langchain-astradb-0.3.3 langchain-community-0.2.4 langchain-core-0.2.5 langchain-google-genai-1.0.6 langchain-google-vertexai-1.0.5 langchain-nvidia-ai-endpoints-0.1.1 langchain-openai-0.1.8 langchain-text-splitters-0.2.1 langdetect-1.0.9 langsmith-0.1.80 llama-index-0.10.43 llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-core-0.10.43 llama-index-embeddings-azure-openai-0.1.7 llama-index-embeddings-bedrock-0.1.4 llama-index-embeddings-gemini-0.1.7 llama-index-embeddings-langchain-0.1.2 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-anthropic-0.1.13 llama-index-llms-azure-openai-0.1.6 llama-index-llms-bedrock-0.1.7 llama-index-llms-gemini-0.1.10 llama-index-llms-openai-0.1.22 llama-index-llms-vertex-0.1.5 llama-index-multi-modal-llms-gemini-0.1.7 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.25 llama-index-readers-llama-parse-0.1.4 llama-index-tools-cassandra-0.1.1 llama-index-vector-stores-astra-db-0.1.7 llama-index-vector-stores-cassandra-0.1.3 llama-parse-0.4.1 llamaindex-py-client-0.1.19 marshmallow-3.21.3 msal-1.28.1 msal-extensions-1.1.0 multiprocess-0.70.16 mypy-extensions-1.0.0 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-1.34.0 ordered-set-4.1.0 orjson-3.10.5 packaging-23.2 pillow-10.3.0 portalocker-2.8.2 pyarrow-14.0.1 pypdf-4.2.0 python-dotenv-1.0.1 python-iso639-2024.4.27 python-magic-0.4.27 ragstack-ai-1.0.8 ragstack-ai-colbert-1.0.5 ragstack-ai-langchain-1.1.0 ragstack-ai-llamaindex-1.0.6 rapidfuzz-3.9.3 requests-2.32.3 requests-toolbelt-1.0.0 s3transfer-0.10.1 smmap-5.0.1 striprtf-0.0.26 tiktoken-0.7.0 torch-2.2.1 triton-2.2.0 typing-inspect-0.9.0 ujson-5.10.0 unstructured-0.14.2 unstructured-client-0.23.7 uuid6-2024.1.12 xxhash-3.4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "19c0fd1f413c445aa595f6f599a13014",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install ragstack-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0YiJSFzDjZS"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID=\"proud-shoreline-426707-s1\"\n",
        "REGION=\"us-central1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXHB8HpoFXjc"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "PROJECT_ID=userdata.get('PROJECT_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTkK-GDMFae1"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "LOCATION=userdata.get('REGION')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcGlO_QGFvQ2"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuN9_9tsF7l7"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GCP_PROJECT_ID\"]=PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_NjHY09GEqG"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LOCATION\"]=LOCATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F38PFsARHYfD",
        "outputId": "de726f60-1b0a-4124-d310-d501e6a746f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "!gcloud config set project {os.getenv(\"GCP_PROJECT_ID\")}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM5dYlFKJhB7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import auth as google_auth\n",
        "  google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrGPGoRFOmMK",
        "outputId": "7f84c056-c20b-4393-dec7-0833473f0559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Credentialed Accounts\n",
            "ACTIVE  ACCOUNT\n",
            "*       garima.solanki18@gmail.com\n",
            "\n",
            "To set the active account, run:\n",
            "    $ gcloud config set account `ACCOUNT`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkW9YvMcPZI1"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "model=GenerativeModel(\"gemini-1.0-pro\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "2Pz0kG_fQLk2",
        "outputId": "a6f3a5c0-3602-4717-fb3e-68ea156ee9e3"
      },
      "outputs": [
        {
          "ename": "PermissionDenied",
          "evalue": "403 Vertex AI API has not been used in project proud-shoreline-426707-s1 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=proud-shoreline-426707-s1 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=proud-shoreline-426707-s1\"\n}\n, reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/proud-shoreline-426707-s1\"\n}\nmetadata {\n  key: \"service\"\n  value: \"aiplatform.googleapis.com\"\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Vertex AI API has not been used in project proud-shoreline-426707-s1 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=proud-shoreline-426707-s1 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:74.125.199.95:443 {grpc_message:\"Vertex AI API has not been used in project proud-shoreline-426707-s1 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=proud-shoreline-426707-s1 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\", grpc_status:7, created_time:\"2024-06-19T11:25:20.352517129+00:00\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-150469ade88b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresposne\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"what is a color of sky?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresposne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, stream)\u001b[0m\n\u001b[1;32m    522\u001b[0m             )\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             return self._generate_content(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mtool_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         )\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mgapic_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prediction_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgapic_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   2126\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDenied\u001b[0m: 403 Vertex AI API has not been used in project proud-shoreline-426707-s1 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=proud-shoreline-426707-s1 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/aiplatform.googleapis.com/overview?project=proud-shoreline-426707-s1\"\n}\n, reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"consumer\"\n  value: \"projects/proud-shoreline-426707-s1\"\n}\nmetadata {\n  key: \"service\"\n  value: \"aiplatform.googleapis.com\"\n}\n]"
          ]
        }
      ],
      "source": [
        "resposne=model.generate_content(\"what is a color of sky?\")\n",
        "resposne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngbo3JaTQp6K"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_API_ENDPOINT=\"https://107d8332-edfe-48b2-9d81-99f7a604dc64-us-east-2.apps.astra.datastax.com\"\n",
        "ASTRA_DB_APPLICATION_TOKEN=\"AstraCS:yGqsDjxTcnPbTzWKBPCqrNaY:f90ebec29d5ca70086bea6e300547c39ec83999a1ee509096abfbb7025a9db26\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW0QMyuJOUGH"
      },
      "outputs": [],
      "source": [
        "os.environ[\"ASTRA_DB_ENDPOINT\"]=ASTRA_DB_API_ENDPOINT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWHikL5ROV_S"
      },
      "outputs": [],
      "source": [
        "os.environ[\"ASTRA_DB_TOKEN\"]=ASTRA_DB_APPLICATION_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj-rrXvuPtvb"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        "    Image,\n",
        "    Part\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEZi6hQ9VT_G"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Create a numbered list of 10 items. Each item in the list should be a trend in the tech industry.\n",
        "\n",
        "Each trend should be less than 5 words.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0drv5VTcVWDI"
      },
      "outputs": [],
      "source": [
        "response=model.generate_content(prompt, stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63HekGL-Vwhl"
      },
      "outputs": [],
      "source": [
        "for response in response:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqY5pzy7VxSl"
      },
      "outputs": [],
      "source": [
        "generation_config =GenerationConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=1.0,\n",
        "    top_k=32,\n",
        "    candidate_count=1,\n",
        "    max_output_tokens=8192,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNuAVnyyV8SB"
      },
      "outputs": [],
      "source": [
        "response=model.generate_content(prompt,generation_config=generation_config, stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJph2_6Va2Wm"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wckm4zyza6pE"
      },
      "outputs": [],
      "source": [
        "source_img_data =requests.get(\"https://drive.google.com/uc?export=view&id=15ddcn-AIxpvRdWcFGvIr77XLWdo4Maof\").content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('coffee_maker_part.png', 'wb') as handler:\n",
        "  handler.write(source_img_data)"
      ],
      "metadata": {
        "id": "JotuieFeb9Zq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "\n",
        "\n",
        "from langchain.schema.messages import HumanMessage\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "import os, sys\n",
        "\n",
        "\n",
        "\n",
        "chat = ChatVertexAI(model_name=\"gemini-1.0-pro-vision\")"
      ],
      "metadata": {
        "id": "KMDS2Jxbdef7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_message = {\n",
        "\n",
        "    \"type\": \"image_url\",\n",
        "\n",
        "    \"image_url\": {\"url\": \"coffee_maker_part.png\"},\n",
        "\n",
        "}\n",
        "\n",
        "text_message = {\n",
        "\n",
        "    \"type\": \"text\",\n",
        "\n",
        "    \"text\": \"What is this image? Share a link to purchase a replacement\",\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "_XiPNaBPfS5d"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message =HumanMessage(content=[text_message, image_message])"
      ],
      "metadata": {
        "id": "wh2Ke3-0f9DE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s3lXE_rgAM0",
        "outputId": "6eb34ba5-b0ef-4b55-f328-87e7fcc08bac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessage(content=[{'type': 'text', 'text': 'What is this image? Share a link to purchase a replacement'}, {'type': 'image_url', 'image_url': {'url': 'coffee_maker_part.png'}}])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat([message]).content)"
      ],
      "metadata": {
        "id": "ptdxmG6egDfw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOAQyCjPeArVbdo/iZwu70z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}